{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# For clustering\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files from 'data' directory\n",
    "csv_files = glob.glob(os.path.join(\"data\", \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Pandas DataFrames from CSV files\n",
    "df_all = [pd.read_csv(file) for file in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames\n",
    "df = pd.concat(df_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'tail_number' column (due to missing values and insignificance)\n",
    "df = df.drop(['tail_number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values across all columns other than the departure and arrival columns (cancelled flights)\n",
    "df = df.dropna(subset=df.columns.difference(['actual_departure_dt', 'actual_arrival_dt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "date_columns = ['date', 'scheduled_departure_dt', 'scheduled_arrival_dt', 'actual_departure_dt', 'actual_arrival_dt']\n",
    "\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add categorised delay time features to data\n",
    "from utils import categorise_delay\n",
    "\n",
    "\n",
    "df['departure_delay_category'] = df['departure_delay'].apply(categorise_delay)\n",
    "df['arrival_delay_category'] = df['arrival_delay'].apply(categorise_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/oskarhibbert/Library/Mobile Documents/com~apple~CloudDocs/Documents/Studies/MSc Sem 1/02807 Computational Tools for Data Science/Project/02807_project/clustering.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oskarhibbert/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/Studies/MSc%20Sem%201/02807%20Computational%20Tools%20for%20Data%20Science/Project/02807_project/clustering.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m station_col \u001b[39min\u001b[39;00m station_columns:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oskarhibbert/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/Studies/MSc%20Sem%201/02807%20Computational%20Tools%20for%20Data%20Science/Project/02807_project/clustering.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m weather_col \u001b[39min\u001b[39;00m weather_columns:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oskarhibbert/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/Studies/MSc%20Sem%201/02807%20Computational%20Tools%20for%20Data%20Science/Project/02807_project/clustering.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         df \u001b[39m=\u001b[39m categorise_weather(df, weather_col, station_col)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Studies/MSc Sem 1/02807 Computational Tools for Data Science/Project/02807_project/utils.py:29\u001b[0m, in \u001b[0;36mcategorise_weather\u001b[0;34m(df, weather_col, station_col)\u001b[0m\n\u001b[1;32m     20\u001b[0m conditions \u001b[39m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m     (df[weather_col] \u001b[39m<\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m]),  \u001b[39m# Much Lower than average\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     (df[weather_col] \u001b[39m<\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m]),              \u001b[39m# Lower than average\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     (df[weather_col] \u001b[39m<\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m]),  \u001b[39m# Higher than average\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     (df[weather_col] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m])  \u001b[39m# Much Higher than average\u001b[39;00m\n\u001b[1;32m     25\u001b[0m ]\n\u001b[1;32m     27\u001b[0m categories \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m df[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mweather_col\u001b[39m}\u001b[39;00m\u001b[39m_category\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mselect(conditions, categories, default\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAverage\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Add categorised weather condition features to data\n",
    "from utils import categorise_weather\n",
    "import numpy as np\n",
    "\n",
    "station_columns = ['STATION_x', 'STATION_y']\n",
    "weather_columns = ['HourlyDryBulbTemperature_x', 'HourlyPrecipitation_x', 'HourlyStationPressure_x', 'HourlyVisibility_x', 'HourlyWindSpeed_x', 'HourlyDryBulbTemperature_y', 'HourlyPrecipitation_y', 'HourlyStationPressure_y', 'HourlyVisibility_y', 'HourlyWindSpeed_y']\n",
    "\n",
    "for station_col in station_columns:\n",
    "    for weather_col in weather_columns:\n",
    "        df = categorise_weather(df, weather_col, station_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = df[['HourlyDryBulbTemperature_x', 'HourlyPrecipitation_x', 'HourlyStationPressure_x', 'HourlyVisibility_x', 'HourlyWindSpeed_x',\n",
    "                       'HourlyDryBulbTemperature_y', 'HourlyPrecipitation_y', 'HourlyStationPressure_y', 'HourlyVisibility_y', 'HourlyWindSpeed_y']]\n",
    "scaler = StandardScaler()\n",
    "scaled_weather_features = scaler.fit_transform(weather_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method for K-Means\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    kmeans.fit(scaled_weather_features)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "# Choose the number of clusters from the Elbow Method\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(scaled_weather_features)\n",
    "df['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "# Hierarchical Clustering\n",
    "# Plotting the dendogram to find the number of clusters\n",
    "plt.figure(figsize=(10,7))\n",
    "dendogram = sch.dendogram(sch.linkage(scaled_weather_features, method='ward'))\n",
    "plt.title('Dendogram')\n",
    "plt.xlabel('Flights')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is number of clusters correct based on Dendogram??\n",
    "hc_labels = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "df['hierarchical_cluster'] = hc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5) # Adjust eps and min_samples\n",
    "dbscan_labels = dbscan.fit_predict(scaled_weather_features)\n",
    "df['dbscan_cluster'] = dbscan_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of clustering\n",
    "print(\"K-Means Clustering\")\n",
    "print(df.groupby('kmeans_cluster').mean())\n",
    "\n",
    "print(\"\\nHierarchical Clustering Results\")\n",
    "print(df.groupby('kmeans_cluster').mean())\n",
    "\n",
    "print(\"\\nHierarchical Clustering Results\")\n",
    "print(df.groupby('hierarchical_cluster').mean())\n",
    "\n",
    "# NOTE: for DBSCAN '-1' labels indicate noise points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
