{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# For clustering\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files from 'data' directory\n",
    "csv_files = glob.glob(os.path.join(\"data\", \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Pandas DataFrames from CSV files\n",
    "df_all = [pd.read_csv(file) for file in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames\n",
    "df = pd.concat(df_all, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'tail_number' column (due to missing values and insignificance)\n",
    "df = df.drop(['tail_number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values across all columns other than the departure and arrival columns (cancelled flights)\n",
    "df = df.dropna(subset=df.columns.difference(['actual_departure_dt', 'actual_arrival_dt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "date_columns = ['date', 'scheduled_departure_dt', 'scheduled_arrival_dt', 'actual_departure_dt', 'actual_arrival_dt']\n",
    "\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add categorised delay time features to data\n",
    "from utils import categorise_delay\n",
    "\n",
    "\n",
    "df['departure_delay_category'] = df['departure_delay'].apply(categorise_delay)\n",
    "df['arrival_delay_category'] = df['arrival_delay'].apply(categorise_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add categorised weather condition features to data\n",
    "from utils import categorise_weather\n",
    "\n",
    "\n",
    "station_columns = ['STATION_x', 'STATION_y']\n",
    "weather_columns = ['HourlyDryBulbTemperature_x', 'HourlyPrecipitation_x', 'HourlyStationPressure_x', 'HourlyVisibility_x', 'HourlyWindSpeed_x', 'HourlyDryBulbTemperature_y', 'HourlyPrecipitation_y', 'HourlyStationPressure_y', 'HourlyVisibility_y', 'HourlyWindSpeed_y']\n",
    "\n",
    "for station_col in station_columns:\n",
    "    for weather_col in weather_columns:\n",
    "        df = categorise_weather(df, weather_col, station_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = df[['HourlyDryBulbTemperature_x', 'HourlyPrecipitation_x', 'HourlyStationPressure_x', 'HourlyVisibility_x', 'HourlyWindSpeed_x',\n",
    "                       'HourlyDryBulbTemperature_y', 'HourlyPrecipitation_y', 'HourlyStationPressure_y', 'HourlyVisibility_y', 'HourlyWindSpeed_y']]\n",
    "scaler = StandardScaler()\n",
    "scaled_weather_features = scaler.fit_transform(weather_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method for K-Means\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    kmeans.fit(scaled_weather_features)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "# Choose the number of clusters from the Elbow Method\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(scaled_weather_features)\n",
    "df['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "# Hierarchical Clustering\n",
    "# Plotting the dendogram to find the number of clusters\n",
    "plt.figure(figsize=(10,7))\n",
    "dendogram = sch.dendogram(sch.linkage(scaled_weather_features, method='ward'))\n",
    "plt.title('Dendogram')\n",
    "plt.xlabel('Flights')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is number of clusters correct based on Dendogram??\n",
    "hc_labels = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "df['hierarchical_cluster'] = hc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5) # Adjust eps and min_samples\n",
    "dbscan_labels = dbscan.fit_predict(scaled_weather_features)\n",
    "df['dbscan_cluster'] = dbscan_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of clustering\n",
    "print(\"K-Means Clustering\")\n",
    "print(df.groupby('kmeans_cluster').mean())\n",
    "\n",
    "print(\"\\nHierarchical Clustering Results\")\n",
    "print(df.groupby('kmeans_cluster').mean())\n",
    "\n",
    "print(\"\\nHierarchical Clustering Results\")\n",
    "print(df.groupby('hierarchical_cluster').mean())\n",
    "\n",
    "# NOTE: for DBSCAN '-1' labels indicate noise points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
